---
title: "Spatial Autocorrelation"
author: "Me"
date: "November 4, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Much of spatial analysis deals with understanding how objects or attributes are clustered together. In general, we consider random distributions, uniform distributions, and clustered distributions to be the focus of our analysis. The statistics used to analyze these clusters are therefore, trying to tell us how closely related objects are in space. 
When dealing with spatial data we must also considered that objects next to each other may have influence on one another. That is, objects in space are not, in fact indepdent, but are rather dependent and the intensity of dependencies varies by how close two objects or neighborhoods are to each other. The statistics must reflect this dependency and are the proccess of relating clustered values together is known as spatial autocorrelation. 
First we must understand what statistics we will want to use in order to spatial autocorrelation. We will go over

*Moran's I
*Geary's C
*Join Count
*Getis Ord Gi and Gi star

We need a few packages
```{r}
library(curl)
library(ape) #you may need to install this package first
library(spdep)
library(raster)
library(pgirmess)
```

Let's load in a data set. This data set is about the spatial location and attributes of different tree species in teh Harvard Forest. 
```{r}
HTrees <- read.csv("http://harvardforest.fas.harvard.edu/data/p03/hf032/hf032-01-tree.csv")
head(HTrees)
HTrees
```
Now lets look at some species
```{r}
# Create subset of data for Acer rubrum
acru <- subset(HTrees, species == "ACRU" & dbh91 != "NA", select = c("xsite", "ysite", "dbh91"))
# Create subset of data for Prunus serotina
plot(acru$xsite, acru$ysite)
prse <- subset(HTrees, species == "PRSE" & dbh91 != "NA", select = c("xsite", "ysite", "dbh91"))
# Create subset of data for Pinus strobus
plot(prse$xsite, prse$ysite)
pist <- subset(HTrees, species == "PIST" & dbh91 != "NA", select = c("xsite", "ysite", "dbh91"))
plot(pist$xsite, pist$ysite)
```
We will be looking at three tree species. Each subset of data needs an x and y coordinate as well as an attribute that we will be measuring. In this case the attribute is diameter to breast height. 

Now we will compute a join count analysis for the three tree species. Join count analysis looks at spatial clustering of two character variables such as prescence or abscence data. It can also be used for data such as defining clustering between republican versus democratic voting states for example. 

For join count analysis we need to create a grid of prescence and abscence from our tree data. 
```{r}
# Convert tree data to SpatialPointsDataFrame, both for entire dataset, and # for individual species. You will need the package pgirmess for this. 
HTrees.spdf <- HTrees
coordinates(HTrees.spdf) <- c("xsite", "ysite")
pist.spdf <- pist
coordinates(pist.spdf) <- c("xsite", "ysite")
acru.spdf <- acru
coordinates(acru.spdf) <- c("xsite", "ysite")
prse.spdf <- prse
coordinates(prse.spdf) <- c("xsite", "ysite")

#Define the extent for the join count analyses
jc.extent <- extent(-300,100,-700,-200)
#set up a blank raster
r <- raster(nrows=25, ncols=20, ext=jc.extent)

acru.rast<-rasterize(acru.spdf, r, field = 1)
acru.rast[is.na(acru.rast)] <- 0
# You can plot the result
plot(acru.rast)
# You can plot the points on top of the raster to verify it is correct
# Remember - we only made the raster for a subset of the data, so there will # be points in a larger area than the raster covers
plot(acru.spdf, add = TRUE)

# Generate neighbors list - the function is 'cell2nb' and the arguments are
# the number of rows and colums in your grid; you can simply get those
# characteristics from your any of your rasters using 'nrow' and 'ncol'
# commands, nested in the cell2nb function (as ilustrated below). Note, the
# default for this is 'rook', but you can change the join counts to 'queen'
# by adding the argument 'type='queen'.
nb <- cell2nb(nrow = nrow(acru.rast), ncol = ncol(acru.rast))
# To calculate neighbors for queen configuration
nb.queen <- cell2nb(nrow = nrow(acru.rast), ncol = ncol(acru.rast), type = "queen")
# Convert the neighbors list to a 'weights' list; again, this will be the
# same for all species we are analyzing. You an follow the example below
# using 'style='B' (as a Binary weights matrix). Again, calculate this for
# the queen setup as well as the default (rook) setup.
lwb <- nb2listw(nb, style = "B")
lwb.queen <- nb2listw(nb.queen, style = "B")

# First, the regular join count test for Acer rubrum (Testing the hypothesis
# of aggregation among like categories; add the argument 'alternative='less'
# to reverse this)
joincount.test(as.factor(acru.rast@data@values), lwb, alternative = "greater") # Second, the permutation-based join count test; similar to above, and you
# can adjust the number of simulations with the 'nsim' argument
joincount.mc(as.factor(acru.rast@data@values), lwb, nsim = 999, alternative = "greater")
# Can also compute these for the queen setup; for example, with the
# permutation test:
joincount.mc(as.factor(acru.rast@data@values), lwb.queen, nsim = 999, alternative = "greater")
```
Now lets perform this test with some random data we created!

This is the data where both points and attributes is clumped
```{r}
c <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Clumped")
e <- read.csv(c, header = TRUE, sep = ",", stringsAsFactors = FALSE)
e
as.numeric(e$att)
?plot
plot(e$x, e$y)
e.spdf <- e
head(e.spdf)
coordinates(e.spdf) <- c("x1", "y1") #as you can see we already have spatial data

jc.extent <- extent(0,100,0,100)
#set up a blank raster
r <- raster(nrows=25, ncols=20, ext=jc.extent)

e.rast<-rasterize(e.spdf, r, field = 1)
e.rast[is.na(e.rast)] <- 0
# You can plot the result
plot(e.rast)
# You can plot the points on top of the raster to verify it is correct
# Remember - we only made the raster for a subset of the data, so there will # be points in a larger area than the raster covers
plot(e.spdf, add = TRUE)

nb <- cell2nb(nrow = nrow(e.rast), ncol = ncol(e.rast))
# To calculate neighbors for queen configuration
nb.queen <- cell2nb(nrow = nrow(e.rast), ncol = ncol(e.rast), type = "queen")
# Convert the neighbors list to a 'weights' list; again, this will be the
# same for all species we are analyzing. You an follow the example below
# using 'style='B' (as a Binary weights matrix). Again, calculate this for
# the queen setup as well as the default (rook) setup.
lwb <- nb2listw(nb, style = "B")
lwb.queen <- nb2listw(nb.queen, style = "B")

# First, the regular join count test for Acer rubrum (Testing the hypothesis
# of aggregation among like categories; add the argument 'alternative='less'
# to reverse this)
joincount.test(as.factor(e.rast@data@values), lwb, alternative = "greater") # Second, the permutation-based join count test; similar to above, and you
# can adjust the number of simulations with the 'nsim' argument
joincount.mc(as.factor(e.rast@data@values), lwb, nsim = 999, alternative = "greater")
# Can also compute these for the queen setup; for example, with the
# permutation test:
joincount.mc(as.factor(e.rast@data@values), lwb.queen, nsim = 999, alternative = "greater")
```



We will be using data created for this module, which is in the repository.
To start we will pull in a dataset with a random distribution
```{r}
f <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Random")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
d
as.numeric(d$att) #for some reason our attribute data is character data so we need to convert it.
plot(d$x, d$y)

```

This is the data where attributes are mixed, but the data is clumped
```{r}
v <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_ExtraClumped")
w <- read.csv(v, header = TRUE, sep = ",", stringsAsFactors = FALSE)
w
as.numeric(w$att)
plot(w$x, w$y)
```

This is for a dataset with different distributions
```{r}
m <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Mixed")
n <- read.csv(m, header = TRUE, sep = ",", stringsAsFactors = FALSE)
n
as.numeric(n$att)
plot(n$x, n$y)
```


