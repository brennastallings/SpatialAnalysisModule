---
title: "Spatial Autocorrelation"
author: "Me"
date: "November 4, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Much of spatial analysis deals with understanding how objects or attributes are clustered together. In general, we consider random distributions, uniform distributions, and clustered distributions to be the focus of our analysis. The statistics used to analyze these clusters are therefore, trying to tell us how closely related objects are in space. 
When dealing with spatial data we must also considered that objects next to each other may have influence on one another. That is, objects in space are not, in fact indepdent, but are rather dependent and the intensity of dependencies varies by how close two objects or neighborhoods are to each other. The statistics must reflect this dependency and are the proccess of relating clustered values together is known as spatial autocorrelation. 
First we must understand what statistics we will want to use in order to spatial autocorrelation. We will go over

*Moran's I
*Geary's C
*Join Count
*Getis Ord Gi and Gi star

We need a few packages
```{r}
library(curl)
library(ape) #you may need to install this package first
library(spdep)
library(ncf)
```


We will be using data created for this module, which is in the repository.
To start we will pull in a dataset with a random distribution
```{r}
f <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Random")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
d
as.numeric(d$att) #for some reason our attribute data is character data so we need to convert it.
```

This is the data where everything is clumped
```{r}
c <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Clumped")
e <- read.csv(c, header = TRUE, sep = ",", stringsAsFactors = FALSE)
e
as.numeric(e$att)
?plot
plot(e$x, e$y)
```

This is for a dataset with different distributions
```{r}
m <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Mixed")
n <- read.csv(m, header = TRUE, sep = ",", stringsAsFactors = FALSE)
n
as.numeric(n$att)
```

Let us start with Moran's I. This statistic uses a spatial weights matrix, the most common of which is an inverse distance matrix. You can always use a different weights matrix depending on the type of data you have. 

First we must create the matrix. 
```{r}
inf.distsd <- as.matrix(dist(cbind(lon=d$x, lat=d$y)))
inf.dists.invd <- 1/inf.dists
diag(inf.dists.invd) <- 0 # we need the diagnol values to equal 0 for this matrix

#repeat for our other two datasets
inf.distse <- as.matrix(dist(cbind(lon=e$x, lat=e$y)))
inf.dists.inve <- 1/inf.dists
diag(inf.dists.inve) <- 0 

inf.distsn <- as.matrix(dist(cbind(lon=n$x, lat=n$y)))
inf.dists.invn <- 1/inf.dists
diag(inf.dists.invn) <- 0 

```

Now we can calculate Moran's I using the ape package
```{r}
#For random data
Moran.I(d$att, inf.dists.invd)
```
```{r}
#For clumped data
Moran.I(e$att, inf.dists.inve)
?Moran.I
```
```{r}
#For in between clumped and random data
Moran.I(n$att, inf.dists.invn)
```
Hmmm so it looks like none of our data is actually correlated spatially. The problem here is that we are not specifying any distance that define neighborhoods. If the data is plotted on a 100 by 100 mark plot, then we see obvious clumping of data. But if we have intervals of five, then the data no longer seems clumped. 

Lets try using the spdep package instead using data = d
```{r}
#first we need to set up the weights matrix
?mat2listw
sample.metric.dists.inv.listw <-mat2listw(inf.dists.invd)
?dnearneigh #creates distinct neighborhoods instead of continuous ones
neighborhood30 <- dnearneigh(cbind(d$y, d$x), 0, 30)
neighborhood30.listw <- nb2listw(neighborhood30, style="B")
moran.test(d$att, sample.metric.dists.inv.listw, alternative = "two.sided")
```
CHALLENGE
The Moran's I statistic standard deviate is negative which points to randomization of the data. Try playing with the neighborhood weights and see if this changes. What happens when neighborhood weigh is set 0 to 10. What happens when the neighhood weights are set from 0 to 1000. Why do you get these results. 

Lets try seeing what happens with clumped data
```{r}
sample.metric.dists.inv.listw <-mat2listw(inf.dists.inve)
neighborhood30 <- dnearneigh(cbind(e$y, e$x), 0, 10)
neighborhood30.listw <- nb2listw(neighborhood30, style="B")
moran.test(e$att, neighborhood30.listw, alternative = "two.sided")
```
why...




