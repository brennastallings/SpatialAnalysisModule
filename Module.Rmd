---
title: "Spatial Autocorrelation"
author: "Me"
date: "November 4, 2019"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

Much of spatial analysis deals with understanding how objects or attributes are clustered together. In general, we consider random distributions, uniform distributions, and clustered distributions to be the focus of our analysis. The statistics used to analyze these clusters are therefore, trying to tell us how closely related objects are in space. 
When dealing with spatial data we must also considered that objects next to each other may have influence on one another. That is, objects in space are not, in fact indepdent, but are rather dependent and the intensity of dependencies varies by how close two objects or neighborhoods are to each other. The statistics must reflect this dependency and are the proccess of relating clustered values together is known as spatial autocorrelation. 
First we must understand what statistics we will want to use in order to spatial autocorrelation. We will go over

*Moran's I
*Geary's C
*Join Count
*Getis Ord Gi and Gi star

We need a few packages
```{r}
library(curl)
library(ape) #you may need to install this package first
library(spdep)
library(ncf)
```


We will be using data created for this module, which is in the repository.
To start we will pull in a dataset with a random distribution
```{r}
f <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Random")
d <- read.csv(f, header = TRUE, sep = ",", stringsAsFactors = FALSE)
d
as.numeric(d$att) #for some reason our attribute data is character data so we need to convert it.
```

This is the data where everything is clumped
```{r}
c <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Clumped")
e <- read.csv(c, header = TRUE, sep = ",", stringsAsFactors = FALSE)
e
as.numeric(e$att)
?plot
plot(e$x, e$y)
```

This is for a dataset with different distributions
```{r}
m <- curl("https://raw.githubusercontent.com/brennastallings/SpatialAnalysisModule/master/Example_Data_Mixed")
n <- read.csv(m, header = TRUE, sep = ",", stringsAsFactors = FALSE)
n
as.numeric(n$att)
```

Let us start with Moran's I. This statistic uses a spatial weights matrix, the most common of which is an inverse distance matrix. You can always use a different weights matrix depending on the type of data you have. 

First we must create the matrix. 
```{r}
inf.distsd <- as.matrix(dist(cbind(lon=d$x, lat=d$y)))
inf.dists.invd <- 1/inf.dists
diag(inf.dists.invd) <- 0 # we need the diagnol values to equal 0 for this matrix

#repeat for our other two datasets
inf.distse <- as.matrix(dist(cbind(lon=e$x, lat=e$y)))
inf.dists.inve <- 1/inf.dists
diag(inf.dists.inve) <- 0 

inf.distsn <- as.matrix(dist(cbind(lon=n$x, lat=n$y)))
inf.dists.invn <- 1/inf.dists
diag(inf.dists.invn) <- 0 

```

Now we can calculate Moran's I using the ape package
```{r}
#For random data
Moran.I(d$att, inf.dists.invd)
```
```{r}
#For clumped data
Moran.I(e$att, inf.dists.inve)
?Moran.I
```
```{r}
#For in between clumped and random data
Moran.I(n$att, inf.dists.invn)
```
Hmmm so it looks like none of our data is actually correlated spatially. The problem here is that we are not specifying any distance that define neighborhoods. If the data is plotted on a 100 by 100 mark plot, then we see obvious clumping of data. But if we have intervals of five, then the data no longer seems clumped. 

We can use the ncf package to add in spatial weight and define our neighborhoods. Your neighborhood will depend on your data type that you must arbitrarily define. 
```{r}
lisa(d$x, d$y, d$att, neigh = 60, resamp = 500, quiet = TRUE)
#
```




